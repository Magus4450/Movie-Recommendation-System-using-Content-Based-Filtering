{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>João Miguel, Bianca Comparato, Michel Gomes, R...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>August 14, 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>4 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Sci-Fi &amp;...</td>\n",
       "      <td>In a future where the elite inhabit an island ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>Movie</td>\n",
       "      <td>7:19</td>\n",
       "      <td>Jorge Michel Grau</td>\n",
       "      <td>Demián Bichir, Héctor Bonilla, Oscar Serrano, ...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>December 23, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>93 min</td>\n",
       "      <td>Dramas, International Movies</td>\n",
       "      <td>After a devastating earthquake hits Mexico Cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>Movie</td>\n",
       "      <td>23:59</td>\n",
       "      <td>Gilbert Chan</td>\n",
       "      <td>Tedd Chan, Stella Chung, Henley Hii, Lawrence ...</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>December 20, 2018</td>\n",
       "      <td>2011</td>\n",
       "      <td>R</td>\n",
       "      <td>78 min</td>\n",
       "      <td>Horror Movies, International Movies</td>\n",
       "      <td>When an army recruit is found dead, his fellow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>Movie</td>\n",
       "      <td>9</td>\n",
       "      <td>Shane Acker</td>\n",
       "      <td>Elijah Wood, John C. Reilly, Jennifer Connelly...</td>\n",
       "      <td>United States</td>\n",
       "      <td>November 16, 2017</td>\n",
       "      <td>2009</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>80 min</td>\n",
       "      <td>Action &amp; Adventure, Independent Movies, Sci-Fi...</td>\n",
       "      <td>In a postapocalyptic world, rag-doll robots hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>Movie</td>\n",
       "      <td>21</td>\n",
       "      <td>Robert Luketic</td>\n",
       "      <td>Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...</td>\n",
       "      <td>United States</td>\n",
       "      <td>January 1, 2020</td>\n",
       "      <td>2008</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>123 min</td>\n",
       "      <td>Dramas</td>\n",
       "      <td>A brilliant group of students become card-coun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type  title           director  \\\n",
       "0      s1  TV Show     3%                NaN   \n",
       "1      s2    Movie   7:19  Jorge Michel Grau   \n",
       "2      s3    Movie  23:59       Gilbert Chan   \n",
       "3      s4    Movie      9        Shane Acker   \n",
       "4      s5    Movie     21     Robert Luketic   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0  João Miguel, Bianca Comparato, Michel Gomes, R...         Brazil   \n",
       "1  Demián Bichir, Héctor Bonilla, Oscar Serrano, ...         Mexico   \n",
       "2  Tedd Chan, Stella Chung, Henley Hii, Lawrence ...      Singapore   \n",
       "3  Elijah Wood, John C. Reilly, Jennifer Connelly...  United States   \n",
       "4  Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...  United States   \n",
       "\n",
       "          date_added  release_year rating   duration  \\\n",
       "0    August 14, 2020          2020  TV-MA  4 Seasons   \n",
       "1  December 23, 2016          2016  TV-MA     93 min   \n",
       "2  December 20, 2018          2011      R     78 min   \n",
       "3  November 16, 2017          2009  PG-13     80 min   \n",
       "4    January 1, 2020          2008  PG-13    123 min   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0  International TV Shows, TV Dramas, TV Sci-Fi &...   \n",
       "1                       Dramas, International Movies   \n",
       "2                Horror Movies, International Movies   \n",
       "3  Action & Adventure, Independent Movies, Sci-Fi...   \n",
       "4                                             Dramas   \n",
       "\n",
       "                                         description  \n",
       "0  In a future where the elite inhabit an island ...  \n",
       "1  After a devastating earthquake hits Mexico Cit...  \n",
       "2  When an army recruit is found dead, his fellow...  \n",
       "3  In a postapocalyptic world, rag-doll robots hi...  \n",
       "4  A brilliant group of students become card-coun...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('netflix_titles.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_doc(doc: str, lemmatize: bool=True) -> str:\n",
    "    \"\"\" Performs basic cleaning of text data. Takes in a sentence, tokenizes it, removes stopwords, and lemmatizes it.\n",
    "\n",
    "    Args:\n",
    "        doc (str): document to be cleaned\n",
    "        lemmatize (bool, optional): whether to lemmatize or not. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        str: cleaned tokens as a string with ' ' as a delimiter\n",
    "    \"\"\"\n",
    "    if type(doc) != str: return \" \"\n",
    "    \n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokens = tokenizer.tokenize(doc)\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stopword = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stopword]\n",
    "\n",
    "    # Remove punctuations\n",
    "    tokens = [word for word in tokens if word.isalpha() or word.isnumeric()]\n",
    "    \n",
    "    if lemmatize:\n",
    "        # Lemmatize\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data required for feature extraction\n",
    "df[\"processed_description\"] = df[\"description\"].apply(clean_doc)\n",
    "df[\"cleaned_cast\"] = df[\"cast\"].apply(clean_doc, args=(False,))\n",
    "df[\"cleaned_title\"] = df[\"title\"].apply(clean_doc, args=(False,))\n",
    "df[\"cleaned_director\"] = df[\"director\"].apply(clean_doc, args=(False,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the columns into one feature column\n",
    "df[\"feature\"] = df[\"cleaned_title\"].astype(str) + \" \" + df[\"cleaned_director\"].astype(str) + \" \" + df[\"cleaned_cast\"].astype(str) + \" \" + df[\"processed_description\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "Generate a vector for a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all-mpnet-base-v2 -> best general purpose quality\n",
    "# all-MiniLM-L6-v2 -> 5 times fater but still offers good quality\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is total 3631 NaN values.\n",
      "There is total 0 NaN values after replacement.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There is total {sum(df.isna().sum())} NaN values.\")\n",
    "df.fillna(\"\", inplace=True)\n",
    "print(f\"There is total {sum(df.isna().sum())} NaN values after replacement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting required columns into a dictionary to be later consumed by elastic search bulk API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = []\n",
    "for i, row in df.iterrows():\n",
    "    dict_ = {\n",
    "        \"title\" : row[\"title\"],\n",
    "        \"type\" : row[\"type\"],\n",
    "        \"director\": row[\"director\"],\n",
    "        \"cast\": row[\"cast\"],\n",
    "        \"rating\": row[\"rating\"],\n",
    "        \"description\": row[\"description\"],\n",
    "        \"release_year\": row[\"release_year\"],\n",
    "        \"feature_vector\" :model.encode(row[\"feature\"])\n",
    "    }\n",
    "    encoded.append(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7787"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Index in Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ElasticUtil import ElasticUtil\n",
    "\n",
    "eu = ElasticUtil(\"http://localhost:9200\")\n",
    "es = eu.get_elastic_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom mapping to store the feature vector as a dense vector\n",
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 2,\n",
    "        \"number_of_replicas\": 1,\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\n",
    "                \"type\" : \"text\",\n",
    "            },\n",
    "            \"type\": {\n",
    "                \"type\" : \"text\",\n",
    "            },\n",
    "            \"director\": {\n",
    "                \"type\" : \"text\",\n",
    "            },\n",
    "            \"cast\": {\n",
    "                \"type\" : \"text\",\n",
    "            },\n",
    "            \"rating\": {\n",
    "                \"type\" : \"text\",\n",
    "            },\n",
    "            \"description\": {\n",
    "                \"type\" : \"text\",\n",
    "            },\n",
    "            \"release_year\": {\n",
    "                \"type\" : \"integer\",\n",
    "            },\n",
    "            \"feature_vector\":{\n",
    "                \"type\" : \"dense_vector\",\n",
    "                \"dims\" : 384 \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleting the index if it exists\n",
    "es.indices.delete(index=\"netflix\", ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'netflix'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my = es.indices.create(index=\"netflix\", body=settings, ignore=400)\n",
    "my\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generator(df: pd.DataFrame):\n",
    "    \"\"\"Creates a generator for the dataframe to be indexed into Elasticsearch\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be indexed\n",
    "\n",
    "    Raises:\n",
    "        StopIteration: When the generator is exhausted\n",
    "\n",
    "    Yields:\n",
    "        dict : Dictionary containing the data to be indexed\n",
    "    \"\"\"\n",
    "    for i, line in enumerate(df):\n",
    "        yield {\n",
    "            \"_index\": \"netflix\",\n",
    "            \"_id\": i,\n",
    "            \"_source\": {\n",
    "                \"title\" : line['title'],\n",
    "                \"type\" : line['type'],\n",
    "                \"director\": line['director'],\n",
    "                \"cast\": line['cast'],\n",
    "                \"rating\": line['rating'],\n",
    "                \"description\": line['description'],\n",
    "                \"release_year\": line['release_year'],    \n",
    "                \"feature_vector\" : line['feature_vector'],\n",
    "            }\n",
    "        }\n",
    "    raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the generator\n",
    "gen = generator(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator raised StopIteration\n",
      "Data indexing complete!\n"
     ]
    }
   ],
   "source": [
    "# Feeding into the bulk API to index the data\n",
    "try:\n",
    "    res = helpers.bulk(es, gen)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Data indexing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "009377cc554cf5e92a28fe0081e1c9c2e81f5cd6e1b9a377555b5c5135cd0076"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
